{"slide_number": 10, "title": "VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model", "contents": [["Introduction", "- The paper addresses the task of automatically extracting package names and versions affected by security vulnerabilities.\n- Existing databases like NVD and GitHub Advisory contain reports with vulnerability descriptions, affected packages, and versions.\n- Current methods for identifying affected packages have low accuracy due to reliance on smaller models.\n- The proposed framework, VulLibGen, leverages large language models (LLMs) to generate affected package names directly.\n- Techniques like supervised fine-tuning (SFT), in-context learning, retrieval-augmented generation (RAG), and local search are used to improve accuracy.\n- Evaluation shows VulLibGen significantly outperforms existing methods and has practical value, with many submissions accepted by GitHub Advisory.\n\n"], ["Background", "- Existing work on affected package identification typically uses smaller models and ranking/retrieval methods.\n- These methods suffer from lower accuracies due to the large number of packages in ecosystems like Maven and PyPi.\n- Re-ranking with BERT has been used to improve accuracy but still leaves room for improvement.\n- The paper identifies two main challenges with LLM generation: lack of domain knowledge and generating non-existing package names.\n- An empirical study on ChatGPT's incorrect responses shows that post-processing by matching is promising for addressing these challenges.\n\n"], ["Approach", "- The VulLibGen framework employs supervised fine-tuning, in-context learning, retrieval-augmented generation, and a local search technique.\n- Supervised fine-tuning and in-context learning enhance the domain knowledge in LLMs.\n- Retrieval-augmented generation (RAG) ranks existing package names based on similarity scores between vulnerability and package descriptions.\n- A local search technique is used to match the generated output with the closest existing package name, reducing hallucinations.\n- The framework's prompt and detailed steps for each technique are provided.\n\n"], ["Evaluation", "- The evaluation setup includes datasets from GitHub Advisory, focusing on Java, JS, Python, and Go vulnerabilities.\n- Comparative methods include FastXML, LightXML, Chronos, and VulLibMiner.\n- Models evaluated include commercial LLMs (ChatGPT, GPT4) and open-source LLMs (LLaMa, Vicuna).\n- Metrics used are Precision@k, Recall@k, and F1@k.\n- VulLibGen significantly outperforms existing methods in accuracy and efficiency.\n- Ablation studies show the contributions of SFT, RAG, and local search to the overall performance.\n- Real-world performance is validated by submissions to GitHub Advisory, with many accepted and merged.\n\n"], ["Ethical Consideration", "- The paper discusses the use of open-source data and the licenses accompanying these resources.\n- VulLibGen is intended to assist maintainers of vulnerability databases and is consistent with the intended use of GitHub Advisory.\n- Potential misuse includes generating harmful content, but measures are taken to minimize this risk by using reviewed vulnerability data.\n\n"], ["Limitation", "- Challenges in generating long and complex package names due to token length and the number of unique packages.\n- Difficulty in generating package names for languages with limited ecosystem knowledge, such as C/C++.\n- Future work includes enhancing LLM knowledge using techniques like constrained decoding and exploring generation without a commonly used ecosystem.\n\n"], ["Threats", "- External validity threat: the Maven corpus used does not include all Java libraries, especially new or private ones.\n- Internal validity threat: potential instrumentation effects due to faults in the tool or third-party tools.\n- Manual inspection of intermediate results is conducted to ensure accuracy.\n\n"], ["Conclusion", "- VulLibGen is the first framework to use LLM generation for identifying vulnerable packages.\n- It employs retrieval-augmented generation, supervised fine-tuning, and a local search technique to improve accuracy.\n- VulLibGen achieves an accuracy of 0.806, significantly higher than the best SOTA approaches at 0.721.\n- The framework has practical value, with many submissions accepted by GitHub Advisory.\n\n"]]}